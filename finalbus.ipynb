{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a820e0c5-8413-431c-9ea0-436b07cc74e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#andra bus details scrapping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the website\n",
    "URL = \"https://www.redbus.in/online-booking/apsrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Function to scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "# Function to scrape bus details\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Allow the page to load\n",
    "        \n",
    "        # Click the \"View Buses\" button if it exists\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)  # Wait for buses to load\n",
    "            \n",
    "            # Scroll down to load all bus items\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for the page to load more content\n",
    "\n",
    "            # Find bus item details\n",
    "            bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "\n",
    "            # Use XPath to handle both seat availability classes\n",
    "            seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_elements[i].text,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# List to hold all bus details\n",
    "all_bus_details = []\n",
    "\n",
    "# Function to scrape all pages\n",
    "def scrape_all_pages():\n",
    "    for page in range(1, 6):  # There are 5 pages\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)  # Wait for the page to load\n",
    "            \n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            # Iterate over each bus route link and scrape the details\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "# Scrape routes and details from all pages\n",
    "scrape_all_pages()\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('ap_bus_details.csv', index=False)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb699e8-9b1a-4824-a241-31ffbb531c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assam bus data scrapping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the website\n",
    "URL = \"https://www.redbus.in/online-booking/astc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Function to scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "# Function to scrape bus details\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Allow the page to load\n",
    "        \n",
    "        # Click the \"View Buses\" button if it exists\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)  # Wait for buses to load\n",
    "            \n",
    "            # Scroll down to load all bus items\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for the page to load more content\n",
    "\n",
    "            # Find bus item details\n",
    "            bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "\n",
    "            # Use XPath to handle both seat availability classes\n",
    "            seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_elements[i].text,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# List to hold all bus details\n",
    "all_bus_details = []\n",
    "\n",
    "# Function to scrape all pages\n",
    "def scrape_all_pages():\n",
    "    for page in range(1, 6):  # There are 5 pages\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)  # Wait for the page to load\n",
    "            \n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            # Iterate over each bus route link and scrape the details\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "# Scrape routes and details from all pages\n",
    "scrape_all_pages()\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('assam_bus_details.csv', index=False)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df4aaa4-6661-4c37-b8cb-ad859ba14eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bihar bus data scrapping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the website\n",
    "URL = \"https://www.redbus.in/online-booking/bihar-state-road-transport-corporation-bsrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Function to scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "# Function to scrape bus details\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Allow the page to load\n",
    "        \n",
    "        # Click the \"View Buses\" button if it exists\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)  # Wait for buses to load\n",
    "            \n",
    "            # Scroll down to load all bus items\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for the page to load more content\n",
    "\n",
    "            # Find bus item details\n",
    "            bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "\n",
    "            # Use XPath to handle both seat availability classes\n",
    "            seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_elements[i].text,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# List to hold all bus details\n",
    "all_bus_details = []\n",
    "\n",
    "# Function to scrape all pages\n",
    "def scrape_all_pages():\n",
    "    for page in range(1, 6):  # There are 5 pages\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)  # Wait for the page to load\n",
    "            \n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            # Iterate over each bus route link and scrape the details\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "# Scrape routes and details from all pages\n",
    "scrape_all_pages()\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('bihar_bus_details.csv', index=False)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20caf85-c936-4670-9417-d6d292de2ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chandigarh data scrapping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the website\n",
    "URL = \"https://www.redbus.in/online-booking/chandigarh-transport-undertaking-ctu\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Function to scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "# Function to scrape bus details\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Allow the page to load\n",
    "        \n",
    "        # Click the \"View Buses\" button if it exists\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)  # Wait for buses to load\n",
    "            \n",
    "            # Scroll down to load all bus items\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for the page to load more content\n",
    "\n",
    "            # Find bus item details\n",
    "            bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "\n",
    "            # Use XPath to handle both seat availability classes\n",
    "            seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_elements[i].text,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# List to hold all bus details\n",
    "all_bus_details = []\n",
    "\n",
    "# Function to scrape all pages\n",
    "def scrape_all_pages():\n",
    "    for page in range(1, 6):  # There are 5 pages\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)  # Wait for the page to load\n",
    "            \n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            # Iterate over each bus route link and scrape the details\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "# Scrape routes and details from all pages\n",
    "scrape_all_pages()\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('chandigarh_bus_details.csv', index=False)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a635b110-acc2-4db6-b690-b11adc94a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#himachal bus data scrapping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the website\n",
    "URL = \"https://www.redbus.in/online-booking/hrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Function to scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "# Function to scrape bus details\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Allow the page to load\n",
    "        \n",
    "        # Click the \"View Buses\" button if it exists\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)  # Wait for buses to load\n",
    "            \n",
    "            # Scroll down to load all bus items\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for the page to load more content\n",
    "\n",
    "            # Find bus item details\n",
    "            bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "\n",
    "            # Use XPath to handle both seat availability classes\n",
    "            seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_elements[i].text,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# List to hold all bus details\n",
    "all_bus_details = []\n",
    "\n",
    "# Function to scrape all pages\n",
    "def scrape_all_pages():\n",
    "    for page in range(1, 6):  # There are 5 pages\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)  # Wait for the page to load\n",
    "            \n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            # Iterate over each bus route link and scrape the details\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "# Scrape routes and details from all pages\n",
    "scrape_all_pages()\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('himachal_bus_details.csv', index=False)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc73a02-bb05-470c-89e7-1599a1693680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jammu & kashmir bus data scrapping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the website\n",
    "URL = \"https://www.redbus.in/online-booking/jksrtc\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Function to scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "# Function to scrape bus details\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Allow the page to load\n",
    "        \n",
    "        # Click the \"View Buses\" button if it exists\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)  # Wait for buses to load\n",
    "            \n",
    "            # Scroll down to load all bus items\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for the page to load more content\n",
    "\n",
    "            # Find bus item details\n",
    "            bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "\n",
    "            # Use XPath to handle both seat availability classes\n",
    "            seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_elements[i].text,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# List to hold all bus details\n",
    "all_bus_details = []\n",
    "\n",
    "# Function to scrape all pages\n",
    "def scrape_all_pages():\n",
    "    for page in range(1, 3):  # There are 2 pages\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)  # Wait for the page to load\n",
    "            \n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            # Iterate over each bus route link and scrape the details\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "# Scrape routes and details from all pages\n",
    "scrape_all_pages()\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('jk_bus_details.csv', index=False)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c42530b-b6cc-45ea-9f81-97c6a9b78941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kaac bus data scrapping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the website\n",
    "URL = \"https://www.redbus.in/online-booking/kaac-transport\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Function to scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "# Function to scrape bus details\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Allow the page to load\n",
    "        \n",
    "        # Click the \"View Buses\" button if it exists\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)  # Wait for buses to load\n",
    "            \n",
    "            # Scroll down to load all bus items\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for the page to load more content\n",
    "\n",
    "            # Find bus item details\n",
    "            bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "\n",
    "            # Use XPath to handle both seat availability classes\n",
    "            seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_elements[i].text,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# List to hold all bus details\n",
    "all_bus_details = []\n",
    "\n",
    "# Function to scrape all pages\n",
    "def scrape_all_pages():\n",
    "    for page in range(1, 3):  # There are 2 pages\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)  # Wait for the page to load\n",
    "            \n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            # Iterate over each bus route link and scrape the details\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "                    \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "# Scrape routes and details from all pages\n",
    "scrape_all_pages()\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('kaac_bus_details.csv', index=False)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba62869-90b0-4178-bcda-bb45cbc08434",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kadamba bus data scrapping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the website\n",
    "URL = \"https://www.redbus.in/online-booking/ktcl/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Function to scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "# Function to scrape bus details\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Allow the page to load\n",
    "        \n",
    "        # Click the \"View Buses\" button if it exists\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)  # Wait for buses to load\n",
    "            \n",
    "            # Scroll down to load all bus items\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for the page to load more content\n",
    "\n",
    "            # Find bus item details\n",
    "            bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "\n",
    "            # Use XPath to handle both seat availability classes\n",
    "            seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                     \"Price\": price_elements[i].text,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# List to hold all bus details\n",
    "all_bus_details = []\n",
    "\n",
    "# Function to scrape all pages\n",
    "def scrape_all_pages():\n",
    "    for page in range(1, 5):  # There are 4 pages\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)  # Wait for the page to load\n",
    "            \n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            # Iterate over each bus route link and scrape the details\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "# Scrape routes and details from all pages\n",
    "scrape_all_pages()\n",
    "\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('kadamba_bus_details.csv', index=False)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d01e41-f4e9-47c3-b613-d0383b27e566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kerala bus data scrapping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the website\n",
    "URL = \"https://www.redbus.in/online-booking/ksrtc-kerala/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Function to scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "# Function to scrape bus details\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Allow the page to load\n",
    "        \n",
    "        # Click the \"View Buses\" button if it exists\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)  # Wait for buses to load\n",
    "            \n",
    "            # Scroll down to load all bus items\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for the page to load more content\n",
    "\n",
    "            # Find bus item details\n",
    "            bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "\n",
    "            # Use XPath to handle both seat availability classes\n",
    "            seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_elements[i].text,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# List to hold all bus details\n",
    "all_bus_details = []\n",
    "\n",
    "# Function to scrape all pages\n",
    "def scrape_all_pages():\n",
    "    for page in range(1, 3):  # There are 2 pages\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)  # Wait for the page to load\n",
    "            \n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            # Iterate over each bus route link and scrape the details\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "# Scrape routes and details from all pages\n",
    "scrape_all_pages()\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('kerala_bus_details.csv', index=False)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9527b4c4-32b1-4ab4-866c-74b588d3e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#north bengal data scrapping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the website\n",
    "URL = \"https://www.redbus.in/online-booking/north-bengal-state-transport-corporation\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Function to scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "# Function to scrape bus details\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Allow the page to load\n",
    "        \n",
    "        # Click the \"View Buses\" button if it exists\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)  # Wait for buses to load\n",
    "            \n",
    "            # Scroll down to load all bus items\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for the page to load more content\n",
    "\n",
    "            # Find bus item details\n",
    "            bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "\n",
    "            # Use XPath to handle both seat availability classes\n",
    "            seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_elements[i].text,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# List to hold all bus details\n",
    "all_bus_details = []\n",
    "\n",
    "# Function to scrape all pages\n",
    "def scrape_all_pages():\n",
    "    for page in range(1, 6):  # There are 5 pages\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)  # Wait for the page to load\n",
    "            \n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            # Iterate over each bus route link and scrape the details\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "# Scrape routes and details from all pages\n",
    "scrape_all_pages()\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('northbengal_bus_details.csv', index=False)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687ce079-735d-4f67-ba40-4a5eda999e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#punjab bus data scrapping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the website\n",
    "URL = \"https://www.redbus.in/online-booking/pepsu/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Function to scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "# Function to scrape bus details\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Allow the page to load\n",
    "        \n",
    "        # Click the \"View Buses\" button if it exists\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)  # Wait for buses to load\n",
    "            \n",
    "            # Scroll down to load all bus items\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for the page to load more content\n",
    "\n",
    "            # Find bus item details\n",
    "            bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "\n",
    "            # Use XPath to handle both seat availability classes\n",
    "            seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_elements[i].text,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# List to hold all bus details\n",
    "all_bus_details = []\n",
    "\n",
    "# Function to scrape all pages\n",
    "def scrape_all_pages():\n",
    "    for page in range(1, 6):  # There are 5 pages\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)  # Wait for the page to load\n",
    "            \n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            # Iterate over each bus route link and scrape the details\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "# Scrape routes and details from all pages\n",
    "scrape_all_pages()\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('punjab_bus_details.csv', index=False)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ffc32a-ae72-4e10-9c35-9e8490ae39d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rajasthan bus data scraapping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the website\n",
    "URL = \"https://www.redbus.in/online-booking/rsrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Function to scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "# Function to scrape bus details\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Allow the page to load\n",
    "        \n",
    "        # Click the \"View Buses\" button if it exists\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)  # Wait for buses to load\n",
    "            \n",
    "            # Scroll down to load all bus items\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for the page to load more content\n",
    "\n",
    "            # Find bus item details\n",
    "            bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "\n",
    "            # Use XPath to handle both seat availability classes\n",
    "            seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_elements[i].text,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# List to hold all bus details\n",
    "all_bus_details = []\n",
    "\n",
    "# Function to scrape all pages\n",
    "def scrape_all_pages():\n",
    "    for page in range(1, 4):  # There are 3 pages\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)  # Wait for the page to load\n",
    "            \n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            # Iterate over each bus route link and scrape the details\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "# Scrape routes and details from all pages\n",
    "scrape_all_pages()\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('rajasthan_bus_details.csv', index=False)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85fe3fc-148a-4ac8-80f3-b952241880b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#south bengal bus data scrapping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the website\n",
    "URL = \"https://www.redbus.in/online-booking/south-bengal-state-transport-corporation-sbstc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Function to scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "# Function to scrape bus details\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Allow the page to load\n",
    "        \n",
    "        # Click the \"View Buses\" button if it exists\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)  # Wait for buses to load\n",
    "            \n",
    "            # Scroll down to load all bus items\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for the page to load more content\n",
    "\n",
    "            # Find bus item details\n",
    "            bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "\n",
    "            # Use XPath to handle both seat availability classes\n",
    "            seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_elements[i].text,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# List to hold all bus details\n",
    "all_bus_details = []\n",
    "\n",
    "# Function to scrape all pages\n",
    "def scrape_all_pages():\n",
    "    for page in range(1, 6):  # There are 5 pages\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)  # Wait for the page to load\n",
    "            \n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            # Iterate over each bus route link and scrape the details\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    " \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "# Scrape routes and details from all pages\n",
    "scrape_all_pages()\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('sb_bus_details.csv', index=False)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2544d5c8-3387-428a-a61f-ee6b59688f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#telangana bus data scrapping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the website\n",
    "URL = \"https://www.redbus.in/online-booking/tsrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Function to scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "# Function to scrape bus details\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Allow the page to load\n",
    "        \n",
    "        # Click the \"View Buses\" button if it exists\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)  # Wait for buses to load\n",
    "            \n",
    "            # Scroll down to load all bus items\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for the page to load more content\n",
    "\n",
    "            # Find bus item details\n",
    "            bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "\n",
    "            # Use XPath to handle both seat availability classes\n",
    "            seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_elements[i].text,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# List to hold all bus details\n",
    "all_bus_details = []\n",
    "\n",
    "# Function to scrape all pages\n",
    "def scrape_all_pages():\n",
    "    for page in range(1, 4):  # There are 3 pages\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)  # Wait for the page to load\n",
    "            \n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            # Iterate over each bus route link and scrape the details\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "# Scrape routes and details from all pages\n",
    "scrape_all_pages()\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('Telangana_bus_details.csv', index=False)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3e6595-9900-411b-9904-578c7a1500f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uttar pradesh bus data scrapping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the website\n",
    "URL = \"https://www.redbus.in/online-booking/uttar-pradesh-state-road-transport-corporation-upsrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Function to scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "# Function to scrape bus details\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Allow the page to load\n",
    "        \n",
    "        # Click the \"View Buses\" button if it exists\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)  # Wait for buses to load\n",
    "            \n",
    "            # Scroll down to load all bus items\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for the page to load more content\n",
    "\n",
    "            # Find bus item details\n",
    "            bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "\n",
    "            # Use XPath to handle both seat availability classes\n",
    "            seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_elements[i].text,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# List to hold all bus details\n",
    "all_bus_details = []\n",
    "\n",
    "# Function to scrape all pages\n",
    "def scrape_all_pages():\n",
    "    for page in range(1, 6):  # There are 5 pages\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)  # Wait for the page to load\n",
    "            \n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            # Iterate over each bus route link and scrape the details\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "# Scrape routes and details from all pages\n",
    "scrape_all_pages()\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('up_bus_details.csv', index=False)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5609824f-260c-4aef-8823-05bc9ae84aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#west bengal bus data scrapping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the website\n",
    "URL = \"https://www.redbus.in/online-booking/wbtc-ctc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Function to scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "# Function to scrape bus details\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Allow the page to load\n",
    "        \n",
    "        # Click the \"View Buses\" button if it exists\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)  # Wait for buses to load\n",
    "            \n",
    "            # Scroll down to load all bus items\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for the page to load more content\n",
    "\n",
    "            # Find bus item details\n",
    "            bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "\n",
    "            # Use XPath to handle both seat availability classes\n",
    "            seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_elements[i].text,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# List to hold all bus details\n",
    "all_bus_details = []\n",
    "\n",
    "# Function to scrape all pages\n",
    "def scrape_all_pages():\n",
    "    for page in range(1, 6):  # There are 5 pages\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)  # Wait for the page to load\n",
    "            \n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            # Iterate over each bus route link and scrape the details\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "            \n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "# Scrape routes and details from all pages\n",
    "scrape_all_pages()\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('wb_bus_details.csv', index=False)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f274274-6910-415f-b6c2-3eb9fad5f954",
   "metadata": {},
   "outputs": [],
   "source": [
    "#west bengal south bus data scrapping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the website\n",
    "URL = \"https://www.redbus.in/online-booking/west-bengal-transport-corporation?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Function to scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "# Function to scrape bus details\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Allow the page to load\n",
    "        \n",
    "        # Click the \"View Buses\" button if it exists\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)  # Wait for buses to load\n",
    "            \n",
    "            # Scroll down to load all bus items\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for the page to load more content\n",
    "\n",
    "            # Find bus item details\n",
    "            bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "\n",
    "            # Use XPath to handle both seat availability classes\n",
    "            seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_elements[i].text,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# List to hold all bus details\n",
    "all_bus_details = []\n",
    "\n",
    "# Function to scrape all pages\n",
    "def scrape_all_pages():\n",
    "    for page in range(1, 6):  # There are 5 pages\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)  # Wait for the page to load\n",
    "            \n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            # Iterate over each bus route link and scrape the details\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "# Scrape routes and details from all pages\n",
    "scrape_all_pages()\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('westbengalsouth_bus_details.csv', index=False)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de61afc1-5936-4b71-97c9-94f3f98497fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe to csv conversion\n",
    "df1=pd.read_csv(\"C:/Users/ncssa/Downloads/kerala_bus_details.csv\")\n",
    "df2=pd.read_csv(\"C:/Users/ncssa/Downloads/ap_bus_details.csv\")    \n",
    "df3=pd.read_csv(\"C:/Users/ncssa/Downloads/Telangana_bus_details.csv\")\n",
    "df4=pd.read_csv(\"C:/Users/ncssa/Downloads/kadamba_bus_details.csv\")\n",
    "df5=pd.read_csv(\"C:/Users/ncssa/Downloads/rajasthan_bus_details.csv\")\n",
    "df6=pd.read_csv(\"C:/Users/ncssa/Downloads/sb_bus_details.csv\")\n",
    "df7=pd.read_csv(\"C:/Users/ncssa/Downloads/jk_bus_details.csv\")\n",
    "df8=pd.read_csv(\"C:/Users/ncssa/Downloads/himachal_bus_details.csv\")\n",
    "df9=pd.read_csv(\"C:/Users/ncssa/Downloads/assam_bus_details.csv\")\n",
    "df10=pd.read_csv(\"C:/Users/ncssa/Downloads/up_bus_details.csv\")\n",
    "df11=pd.read_csv(\"C:/Users/ncssa/Downloads/wb_bus_details.csv\")\n",
    "df12=pd.read_csv(\"C:/Users/ncssa/Downloads/chandigarh_bus_details.csv\")\n",
    "df13=pd.read_csv(\"C:/Users/ncssa/Downloads/punjab_bus_details.csv\")\n",
    "df14=pd.read_csv(\"C:/Users/ncssa/Downloads/northbengal_bus_details.csv\")\n",
    "df15=pd.read_csv(\"C:/Users/ncssa/Downloads/bihar_bus_details.csv\")\n",
    "df16=pd.read_csv(\"C:/Users/ncssa/Downloads/kaac_bus_details.csv\")\n",
    "df17=pd.read_csv(\"C:/Users/ncssa/Downloads/westbengalsouth_bus_details.csv\")\n",
    "\n",
    "df=pd.concat((df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16,df17),ignore_index=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ed450a0-5c43-4ae3-b658-0496c42c0353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12184 entries, 0 to 12183\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Route_Name         12184 non-null  object \n",
      " 1   Route_Link         12184 non-null  object \n",
      " 2   Bus_Name           12184 non-null  object \n",
      " 3   Bus_Type           12184 non-null  object \n",
      " 4   Departing_Time     12184 non-null  object \n",
      " 5   Duration           12184 non-null  object \n",
      " 6   Reaching_Time      12184 non-null  object \n",
      " 7   Star_Rating        12184 non-null  float64\n",
      " 8   Price              12184 non-null  float64\n",
      " 9   Seat_Availability  12184 non-null  int64  \n",
      "dtypes: float64(2), int64(1), object(7)\n",
      "memory usage: 952.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#data cleaning\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"C:/Users/ncssa/Downloads/bus_routes.csv\")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66bc3a4b-5606-40c0-8e28-c8e5181dd60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         444.0\n",
       "1         488.0\n",
       "2         720.0\n",
       "3         469.0\n",
       "4         720.0\n",
       "          ...  \n",
       "12179    1799.0\n",
       "12180    1999.0\n",
       "12181    1999.0\n",
       "12182    1050.0\n",
       "12183     275.0\n",
       "Name: Price, Length: 12184, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting null\n",
    "df[\"Price\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7e6caf5-4bd3-4bb2-a875-35ea2c9f5e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2.5\n",
       "1        3.2\n",
       "2        4.0\n",
       "3        3.0\n",
       "4        3.7\n",
       "        ... \n",
       "12179    1.6\n",
       "12180    1.6\n",
       "12181    1.6\n",
       "12182    1.5\n",
       "12183    3.3\n",
       "Name: Star_Rating, Length: 12184, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Star_Rating\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0a0f40-18f5-4750-96b7-e0e19fd4c767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time to datetime and then format to HH:MM\n",
    "df['Departing_Time'] = pd.to_datetime(df['Departing_Time'], format='%H:%M:%S').dt.strftime('%H:%M')\n",
    "df['Reaching_Time'] = pd.to_datetime(df['Reaching_Time'], format='%H:%M:%S').dt.strftime('%H:%M')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18622e85-f9b2-43ec-8202-323401e52eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change dataframe to csv\n",
    "path=r\"C:/Users/ncssa/Downloads/bus_routes.csv\"\n",
    "df.to_csv(path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30e1d88-3d4b-4df3-b0de-623d26b7d2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
